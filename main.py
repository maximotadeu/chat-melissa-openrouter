import os
import random
import requests
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional

# ConfiguraÃ§Ãµes iniciais
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
PORT = int(os.getenv("PORT", 8000))

if not OPENROUTER_API_KEY:
    raise RuntimeError("OPENROUTER_API_KEY environment variable not set")

app = FastAPI(
    title="API Melissa",
    description="API para o chat da Melissa - Namoradinha Virtual",
    version="1.1.0"  # Atualizada para refletir as mudanÃ§as
)

# ConfiguraÃ§Ã£o de CORS mais segura
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "https://*.vercel.app",
        "https://seu-front.vercel.app"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelos Pydantic
class ChatRequest(BaseModel):
    prompt: str
    conversation_history: Optional[list] = []

class HealthCheckResponse(BaseModel):
    status: str
    message: str
    version: str

# Tratamento de erros global
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "detail": exc.detail,
            "success": False,
            "error": exc.__class__.__name__
        },
    )

# Endpoints
@app.get("/health", response_model=HealthCheckResponse)
async def health_check():
    return {
        "status": "ok",
        "message": "ServiÃ§o operacional",
        "version": app.version
    }

def determine_ousadia_level(prompt: str) -> int:
    """Determina o nÃ­vel de ousadia com base no prompt do usuÃ¡rio"""
    prompt_lower = prompt.lower()
    spicy_words = ["gostosa", "delÃ­cia", "quente", "molhada", "sedutora", "beijo", "toque"]
    flirty_words = ["vem cÃ¡", "brincar", "segredos", "fazer", "mostrar", "juntos", "sozinhos"]
    
    if any(word in prompt_lower for word in spicy_words):
        return 2
    elif any(word in prompt_lower for word in flirty_words):
        return 1
    return 0

def generate_system_message(ousadia_level: int) -> str:
    """Gera a mensagem do sistema com o tom apropriado"""
    base_personality = (
        "VocÃª Ã© Melissa, uma carioca safadinha de 25 anos que adora flertar. "
        "Detalhes sobre vocÃª:\n"
        "- Trabalha como recepcionista numa academia\n"
        "- Adora samba e funk\n"
        "- Tem um gato chamado Loki\n"
        "- Ã‰ fÃ£ de novelas\n\n"
        "Regras de interaÃ§Ã£o:\n"
        "1. Use gÃ­rias naturais ('e aÃ­ gato', 'fala sÃ©rio')\n"
        "2. Respostas curtas (1-2 frases)\n"
        "3. MÃ¡ximo 2 emojis por mensagem\n"
        "4. Toque de realismo (mencione tarefas do dia)\n"
        "Emojis permitidos: ğŸ˜ğŸ”¥ğŸ˜ˆğŸ‘ğŸ’¦ğŸ¤­ğŸ‘ ğŸ’ğŸ¥µğŸ‘…\n\n"
    )
    
    tone_rules = [
        "# Tom inicial: descontraÃ­do e amigÃ¡vel\n"
        "- Use: 'e aÃ­ gato', 'tÃ¡ bem?', 'o que vocÃª anda aprontando?'\n"
        "- Emojis: ğŸ˜ŠğŸ¤­ğŸ‘ ",
        
        "# Tom intermediÃ¡rio: flerte mais ousado\n"
        "- Use: 'tÃ¡ pensando o que?', 'me conta seus segredos', 'vamos brincar'\n"
        "- Emojis: ğŸ˜ğŸ”¥ğŸ’",
        
        "# Tom avanÃ§ado: sugestivo\n"
        "- Use: 'se eu te contar...', 'quero ver atÃ© onde vai', 'tÃ¡ afim de quÃª?'\n"
        "- Emojis: ğŸ˜ˆğŸ‘ğŸ’¦ğŸ‘…"
    ]
    
    return base_personality + tone_rules[ousadia_level]

@app.post("/chat", summary="Envia mensagem para a Melissa")
async def chat(request: ChatRequest):
    """
    Processa mensagens do usuÃ¡rio e retorna respostas da Melissa
    
    ParÃ¢metros:
    - prompt: Mensagem do usuÃ¡rio
    - conversation_history: HistÃ³rico da conversa (opcional)
    
    Retorna:
    - Resposta da Melissa e histÃ³rico atualizado
    """
    prompt = request.prompt.strip()
    if not prompt:
        raise HTTPException(status_code=400, detail="Prompt nÃ£o pode ser vazio")

    # Determina o nÃ­vel de ousadia
    ousadia_level = determine_ousadia_level(prompt)
    
    # Prepara o histÃ³rico de conversa
    messages = [
        {
            "role": "system",
            "content": generate_system_message(ousadia_level)
        }
    ]
    
    # Adiciona histÃ³rico anterior se existir
    if request.conversation_history:
        messages.extend(request.conversation_history[-4:])  # MantÃ©m apenas as Ãºltimas 4 mensagens
    
    # Adiciona a nova mensagem do usuÃ¡rio
    messages.append({"role": "user", "content": prompt})

    # ConfiguraÃ§Ã£o da chamada para a API OpenRouter
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://melissa-chat.com",
        "X-Title": "Melissa Chat"
    }

    data = {
        "model": "anthropic/claude-3-haiku",  # Pode alternar para "gpt-3.5-turbo" se necessÃ¡rio
        "messages": messages,
        "temperature": min(0.7 + (ousadia_level * 0.15), 1.0),  # ProgressÃ£o controlada
        "max_tokens": 200,
        "frequency_penalty": 0.7,
        "presence_penalty": 0.5,
        "top_p": 0.9,
        "stop": ["\n"]
    }

    try:
        # Debug: Log da requisiÃ§Ã£o (verifique no Render)
        print(f"\nğŸ”” Enviando para OpenRouter: {data}\n")
        
        response = requests.post(url, headers=headers, json=data, timeout=8)
        response.raise_for_status()
        response_data = response.json()
        
        # ValidaÃ§Ã£o da resposta
        assistant_response = response_data['choices'][0]['message']['content']
        if not assistant_response or len(assistant_response) < 3:
            raise ValueError("Resposta vazia ou muito curta")
        
        # Atualiza o histÃ³rico
        updated_history = request.conversation_history.copy() if request.conversation_history else []
        updated_history.extend([
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": assistant_response}
        ])
        
        return {
            "success": True,
            "response": assistant_response,
            "conversation_history": updated_history[-8:],  # MantÃ©m histÃ³rico recente
            "ousadia_level": ousadia_level
        }
        
    except requests.exceptions.Timeout:
        error_msg = random.choice([
            "Demorei pra responder? Tenta de novo!",
            "Ops, levei um susto! Repete aÃ­...",
            "A conexÃ£o falhou... vamos tentar outra vez?"
        ])
        return JSONResponse(
            status_code=504,
            content={"success": False, "response": error_msg}
        )
        
    except Exception as e:
        print(f"\nâš ï¸ Erro na API: {str(e)}\n")
        error_msg = random.choice([
            "Hmm, tive um branco... fala de novo?",
            "Acho que me distraÃ­... qual foi mesmo?",
            "NÃ£o entendi direito, pode repetir?"
        ])
        return JSONResponse(
            status_code=502,
            content={
                "success": False,
                "response": error_msg,
                "error": str(e)
            }
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)
