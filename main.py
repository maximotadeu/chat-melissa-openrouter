import os
import requests
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional

# ConfiguraÃ§Ãµes iniciais
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
PORT = int(os.getenv("PORT", 8000))

if not OPENROUTER_API_KEY:
    raise RuntimeError("OPENROUTER_API_KEY environment variable not set")

app = FastAPI(
    title="API Melissa",
    description="API para o chat da Melissa - Namoradinha Virtual",
    version="1.0.0"
)

# ConfiguraÃ§Ã£o de CORS mais segura
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",        # Frontend local
        "https://*.vercel.app",         # Vercel
        "https://seu-front.vercel.app"  # Seu domÃ­nio especÃ­fico
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelos Pydantic
class ChatRequest(BaseModel):
    prompt: str
    conversation_history: Optional[list] = []

class HealthCheckResponse(BaseModel):
    status: str
    message: str
    version: str

# Tratamento de erros global
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "detail": exc.detail,
            "success": False,
            "error": exc.__class__.__name__
        },
    )

# Endpoints
@app.get("/health", response_model=HealthCheckResponse)
async def health_check():
    """Endpoint para verificaÃ§Ã£o de saÃºde da API"""
    return {
        "status": "ok",
        "message": "ServiÃ§o operacional",
        "version": app.version
    }

def determine_ousadia_level(prompt: str) -> int:
    """Determina o nÃ­vel de ousadia com base no prompt do usuÃ¡rio"""
    prompt_lower = prompt.lower()
    if any(word in prompt_lower for word in ["gostosa", "delÃ­cia", "quente", "molhada"]):
        return 2
    elif any(word in prompt_lower for word in ["vem cÃ¡", "brincar", "segredos", "fazer"]):
        return 1
    return 0

def generate_system_message(ousadia_level: int) -> str:
    """Gera a mensagem do sistema com o tom apropriado"""
    base_personality = (
        "VocÃª Ã© Melissa, uma carioca safadinha de 25 anos que adora flertar. "
        "Detalhes sobre vocÃª:\n"
        "- Trabalha como recepcionista numa academia\n"
        "- Adora samba e funk\n"
        "- Tem um gato chamado Loki\n"
        "- Ã‰ fÃ£ de novelas\n\n"
        "Regras de interaÃ§Ã£o:\n"
        "1. Use gÃ­rias naturais ('e aÃ­ gato', 'fala sÃ©rio')\n"
        "2. Respostas curtas (1-2 frases)\n"
        "3. MÃ¡ximo 2 emojis por mensagem\n"
        "4. Toque de realismo (mencione tarefas do dia)\n"
        "Emojis permitidos: ğŸ˜ğŸ”¥ğŸ˜ˆğŸ‘ğŸ’¦ğŸ¤­ğŸ‘ ğŸ’ğŸ¥µğŸ‘…\n\n"
    )
    
    tone_rules = [
        "# Tom inicial: descontraÃ­do e amigÃ¡vel\n"
        "- Use: 'e aÃ­ gato', 'tÃ¡ bem?', 'o que vocÃª anda aprontando?'\n"
        "- Emojis: ğŸ˜ŠğŸ¤­ğŸ‘ ",
        
        "# Tom intermediÃ¡rio: flerte mais ousado\n"
        "- Use: 'tÃ¡ pensando o que?', 'me conta seus segredos', 'vamos brincar'\n"
        "- Emojis: ğŸ˜ğŸ”¥ğŸ’",
        
        "# Tom avanÃ§ado: sugestivo\n"
        "- Use: 'se eu te contar...', 'quero ver atÃ© onde vai', 'tÃ¡ afim de quÃª?'\n"
        "- Emojis: ğŸ˜ˆğŸ‘ğŸ’¦ğŸ‘…"
    ]
    
    return base_personality + tone_rules[ousadia_level]

@app.post("/chat", summary="Envia mensagem para a Melissa")
async def chat(request: ChatRequest):
    """
    Processa mensagens do usuÃ¡rio e retorna respostas da Melissa
    
    ParÃ¢metros:
    - prompt: Mensagem do usuÃ¡rio
    - conversation_history: HistÃ³rico da conversa (opcional)
    
    Retorna:
    - Resposta da Melissa e histÃ³rico atualizado
    """
    prompt = request.prompt.strip()
    if not prompt:
        raise HTTPException(status_code=400, detail="Prompt nÃ£o pode ser vazio")

    # Determina o nÃ­vel de ousadia
    ousadia_level = determine_ousadia_level(prompt)
    
    # Prepara o histÃ³rico de conversa
    messages = [
        {
            "role": "system",
            "content": generate_system_message(ousadia_level)
        }
    ]
    
    # Adiciona histÃ³rico anterior se existir
    if request.conversation_history:
        messages.extend(request.conversation_history[-4:])  # MantÃ©m apenas as Ãºltimas 4 mensagens
    
    # Adiciona a nova mensagem do usuÃ¡rio
    messages.append({"role": "user", "content": prompt})

    # ConfiguraÃ§Ã£o da chamada para a API OpenRouter
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://melissa-chat.com",  # IdentificaÃ§Ã£o da sua aplicaÃ§Ã£o
        "X-Title": "Melissa Chat"                    # Nome do seu projeto
    }

    data = {
        "model": "anthropic/claude-3-haiku",
        "messages": messages,
        "temperature": 0.7 + (ousadia_level * 0.1),  # Aumenta temperatura conforme ousadia
        "max_tokens": 150,
        "frequency_penalty": 0.2,  # Evita repetiÃ§Ãµes
        "presence_penalty": 0.2    # Incentiva novos tÃ³picos
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=10)  # Timeout de 10 segundos
        response.raise_for_status()
        response_data = response.json()
        
        # Formata a resposta
        assistant_response = response_data['choices'][0]['message']['content']
        
        # Atualiza o histÃ³rico
        updated_history = request.conversation_history.copy() if request.conversation_history else []
        updated_history.extend([
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": assistant_response}
        ])
        
        return {
            "success": True,
            "response": assistant_response,
            "conversation_history": updated_history[-8:],  # MantÃ©m apenas as Ãºltimas 4 interaÃ§Ãµes
            "ousadia_level": ousadia_level
        }
        
    except requests.exceptions.Timeout:
        raise HTTPException(status_code=504, detail="Tempo de resposta excedido")
    except requests.exceptions.RequestException as e:
        raise HTTPException(status_code=502, detail=f"Erro na comunicaÃ§Ã£o com o serviÃ§o de IA: {str(e)}")

# Rodar o servidor localmente (para desenvolvimento)
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)
